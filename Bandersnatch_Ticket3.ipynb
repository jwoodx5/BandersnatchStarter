{"cells": [{"cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [{"name": "stdout",
                         "output_type": "stream",
                         "text": ["Categorical columns:\n",
                                  "Index(['Name', 'Type', 'Rarity', 'Damage', 'Timestamp'], dtype='object')\n",
                                  "RandomForest Best Score: 0.5642\n"]},
                        {"name": "stderr",
                         "output_type": "stream",
                         "text": ["c:\\Users\\jwood\\.virtualenvs\\BandersnatchStarter-9n8Yf6xu\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
                                  "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
                                  "\n",
                                  "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                                  "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                                  "Please also refer to the documentation for alternative solver options:\n",
                                  "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                                  "  n_iter_i = _check_optimize_result(\n"]},
                        {"name": "stdout",
                         "output_type": "stream",
                         "text": ["LogisticRegression Best Score: 0.9883\n",
                                  "GradientBoosting Best Score: 0.8942\n",
                                  "Best Model: LogisticRegression\n",
                                  "Accuracy: 0.9900\n",
                                  "               precision    recall  f1-score   support\n",
                                  "\n",
                                  "Rarity_Rank 0       1.00      1.00      1.00        86\n",
                                  "Rarity_Rank 1       1.00      1.00      1.00        73\n",
                                  "Rarity_Rank 2       1.00      1.00      1.00        50\n",
                                  "Rarity_Rank 3       0.98      1.00      0.99        42\n",
                                  "Rarity_Rank 4       0.95      0.97      0.96        39\n",
                                  "Rarity_Rank 5       1.00      0.80      0.89        10\n",
                                  "\n",
                                  "     accuracy                           0.99       300\n",
                                  "    macro avg       0.99      0.96      0.97       300\n",
                                  " weighted avg       0.99      0.99      0.99       300\n",
                                  "\n",
                                  "\n",
                                  "The best model identified through our training and tuning process is the Logistic Regression model. It achieved the highest cross-validated score of 0.9883 during training and an impressive accuracy of 0.9900 on the test set, outperforming both RandomForest and GradientBoosting classifiers. Logistic Regression, a simple yet powerful linear model, provided excellent precision, recall, and F1 scores across most classes. Its high accuracy and reliability make it the optimal choice for predicting the 'Rarity' of instances based on their features, ensuring consistent and dependable results.\n"]}],
            "source": ["# Imports\n",
                       "import pandas as pd\n",
                       "import numpy as np\n",
                       "from pymongo import MongoClient\n",
                       "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                       "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                       "from sklearn.linear_model import LogisticRegression\n",
                       "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                       "import joblib\n",
                       "\n",
                       "from dotenv import load_dotenv\n",
                       "import os\n",
                       "\n",
                       "# Load environment variables from .env file\n",
                       "load_dotenv()\n",
                       "\n",
                       "# Get the MONGO_URL environment variable\n",
                       "mongo_url = os.getenv('MONGO_URL')\n",
                       "\n",
                       "# Database setup: Connect to MongoDB and select the database and collection\n",
                       "client = MongoClient(mongo_url)\n",
                       "db = client['Database']\n",
                       "collection = db['Database']\n",
                       "\n",
                       "# Data preparation: Fetch data from MongoDB and convert to DataFrame\n",
                       "data = list(collection.find())\n",
                       "df = pd.DataFrame(data)\n",
                       "\n",
                       "# Drop MongoDB's automatic '_id' column if it's present in the DataFrame\n",
                       "if '_id' in df.columns:\n",
                       "    df.drop(columns=['_id'], inplace=True)\n",
                       "\n",
                       "# Initial Data Exploration: Identify categorical columns\n",
                       "print(\"Categorical columns:\")\n",
                       "print(df.select_dtypes(include=['object']).columns)\n",
                       "\n",
                       "# Preprocessing: Encode categorical variables if needed\n",
                       "df_encoded = pd.get_dummies(df, columns=df.select_dtypes(include=['object']).columns.tolist())\n",
                       "\n",
                       "# Define the target and features for modeling\n",
                       "rarity_columns = df_encoded.filter(regex='^Rarity_').columns\n",
                       "X = df_encoded.drop(columns=rarity_columns)\n",
                       "y = df_encoded[rarity_columns].idxmax(axis=1)\n",
                       "\n",
                       "# Split the data into training and testing sets for model evaluation\n",
                       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                       "\n",
                       "# Model training and evaluation: Setup dictionary of models and parameters for tuning\n",
                       "models = {\n",
                       "    'RandomForest': RandomForestClassifier(),\n",
                       "    'LogisticRegression': LogisticRegression(max_iter=200),\n",
                       "    'GradientBoosting': GradientBoostingClassifier()\n",
                       "}\n",
                       "\n",
                       "params = {\n",
                       "    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [5, 10]},\n",
                       "    'LogisticRegression': {'C': [0.1, 1, 10]},\n",
                       "    'GradientBoosting': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
                       "}\n",
                       "\n",
                       "# Initialize a dictionary to store the best models\n",
                       "best_models = {}\n",
                       "\n",
                       "# Train each model using GridSearchCV\n",
                       "for name, model in models.items():\n",
                       "    grid = GridSearchCV(model, params[name], cv=3, scoring='accuracy', n_jobs=-1)\n",
                       "    grid.fit(X_train, y_train)\n",
                       "    best_models[name] = grid.best_estimator_\n",
                       "    print(f\"{name} Best Score: {grid.best_score_:.4f}\")\n",
                       "\n",
                       "# Select and report the best model based on the test accuracy\n",
                       "best_model_name = max(best_models, key=lambda name: best_models[name].score(X_test, y_test))\n",
                       "best_model = best_models[best_model_name]\n",
                       "best_accuracy = best_model.score(X_test, y_test)\n",
                       "\n",
                       "print(f\"Best Model: {best_model_name}\")\n",
                       "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
                       "\n",
                       "# Save the best model to disk using joblib\n",
                       "joblib.dump(best_model, 'best_model.joblib')\n",
                       "\n",
                       "# Load the model from disk to confirm it can be loaded successfully\n",
                       "loaded_model = joblib.load('best_model.joblib')\n",
                       "assert loaded_model.score(X_test, y_test) == best_accuracy\n",
                       "\n",
                       "# Generate and display a classification report\n",
                       "predictions = best_model.predict(X_test)\n",
                       "print(classification_report(y_test, predictions))\n",
                       "\n",
                       "# Summary of the best model\n",
                       "\"\"\"\n",
                       "The best model identified through our training and tuning process is \n",
                       "the Logistic Regression model. It achieved the highest \n",
                       "cross-validated score of 0.9883 during training \n",
                       "and an impressive accuracy of 0.9900 on the test set, \n",
                       "outperforming both RandomForest and GradientBoosting classifiers. \n",
                       "Logistic Regression, a simple yet powerful linear model, \n",
                       "provided excellent precision, recall, and F1 scores across most classes. \n",
                       "Its high accuracy and reliability make it the optimal choice \n",
                       "for predicting the 'Rarity' of instances based on their features, \n",
                       "ensuring consistent and dependable results.\n",
                       "\"\"\"\n"]}],
    "metadata": {"kernelspec": {"display_name": "BandersnatchStarter-9n8Yf6xu",
                                "language": "python",
                                "name": "python3"},
                 "language_info": {"codemirror_mode": {"name": "ipython",
                                                       "version": 3},
                                   "file_extension": ".py",
                                   "mimetype": "text/x-python",
                                   "name": "python",
                                   "nbconvert_exporter": "python",
                                   "pygments_lexer": "ipython3",
                                   "version": "3.12.3"}},
    "nbformat": 4,
 "nbformat_minor": 2}
